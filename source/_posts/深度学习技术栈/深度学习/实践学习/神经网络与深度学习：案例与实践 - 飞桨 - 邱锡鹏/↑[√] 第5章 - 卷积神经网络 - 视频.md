---
title: 第5章 - 卷积神经网络 - 视频
date: '2022年12月19日13:00:56'
categories:
  - 深度学习技术栈
  - 深度学习
  - 实践学习
  - 神经网络与深度学习：案例与实践 - 飞桨 - 邱锡鹏
abbrlink: 1033337951
---

---

## [√] 5.1 - 卷积

---

#### [√] 目录

---

![image-20221219130508758](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219143242822.png) 





---

#### [√] 卷积

---

###### [√] 用卷积替代全连接

---

![image-20221219142645749](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219142645749.png)

---

###### [√] 卷积算子

---

![image-20221219143242822](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219130508758.png)

---

###### [√] 二维卷积算子

---



![image-20221219143422307](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219143422307.png)

![image-20221219143509534](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219144446993.png)

![image-20221219143721941](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219143509534.png)



---

###### [√] 二维卷积算子的参数量

---

![image-20221219144138294](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219144809626.png)

> alec：
>
> L层得到30×30个神经元，
>
> 使用全连接的话则需要30×30×32×32≈900000=90万个参数
>
> 使用卷积的话，则需要的参数量为9个（不同的神经元参数共享、单个神经元局部连接，通过这两个来节省参数）

---

###### [√] 二维卷积算子的计算量

---

![image-20221219144446993](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219144634395.png)

---

###### [√] 感受野

---

![image-20221219144634395](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219144943348.png)

---

###### [√] 步长

---

![image-20221219144809626](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219145246003.png)

---

###### [√] 零填充

---

![image-20221219144943348](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219150120256.png)





---

#### [√] 卷积的变种

---

###### [√] 常用的等宽卷积

---

> alec：
>
> 等宽卷积：P = （U - 1）/ 2
>
> 常用等宽卷积的有：resnet、vgg
>
> 等宽卷积举例：卷积核大小3×3，填充P = （3-1）/ 2 = 1

![image-20221219145246003](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219145759222.png)



---

###### [√] 带步长和零填充的二维卷积算子

---

![image-20221219145412085](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219150239521.png)





---

#### [√] 使用卷积完成图像边缘检测任务

---

> alec：
>
> 拉布拉斯算子是一个二维微分算子，能够对边缘进行提取

![image-20221219145722897](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219151258835.png)

---

###### [√] 拉普拉斯算子

---



![image-20221219145759222](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219150542776.png)



---

## [√] 5.2 - 卷积神经网络的基础算子

---

#### [√] 卷积神经网络的基础算子

---

###### [√] 卷积神经网络

---

![image-20221219150120256](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219150735517.png)

---

###### [√] 卷积层算子

---

![image-20221219150239521](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219145722897.png)

---

###### [√] 一张输出特征图的计算

---

![image-20221219150423360](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219161403997.png)

![image-20221219150542776](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219161536118.png)



> alec：
>
> 输出通道数，等于卷积核的个数，也等于输出特征图的深度
>
> 输入特征图的深度一般定义为D，输出特征图的深度一般定义为P



---

#### [√] 卷积层算子

---

###### [√] 多张输出特征图的计算

---

![image-20221219150735517](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219162856215.png)

> alec：
>
> ![image-20221219151258835](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219162715734.png)
>
> 上面这个一层的卷子算子，out_channels为3，表示本层防止了3组卷积核，in_channels为2，表示上一层数据有2层，因此本层的每组卷积核要设置2层，每个卷积核的长宽为kernel_size的平方

---

###### [√] 多通道卷积层算子的参数量

---

> alec：
>
> 参数量：P×D×U×V + P

![image-20221219161403997](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219150423360.png)

---

###### [√] 多通道卷积层算子计算量

---

![image-20221219161536118](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219162318771.png)

> alec：
>
> 一组卷积核对应一个偏置参数

---

#### [√] 汇聚层算子

---

###### [√] 汇聚层算子

---

![image-20221219162318771](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219162922050.png)

> alec：
>
> 汇聚层的参数量都是0，没有需要学习的参数。
>
> 汇聚层的计算量，最大汇聚为0，平均汇聚为M‘×N’×P，即一个输出像素对应1计算量，因为输出有P层特征图，每个特征图为M’×N‘，因此平均汇聚的计算量为如上
>
> 汇聚层帮助减少计算量，但是不会帮助减少参数量

---

## [√] 5.3 - 基于LeNet实现手写数字识别

---

#### [√] 机器学习时间5要素

---

![image-20221219162715734](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219164333869.png)

---

#### [√] 数据

---

###### [√] 数据集介绍

---



![image-20221219162741543](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219162822345.png)

---

###### [√] 数据集分布

---

![image-20221219162822345](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219163725636.png)

---

###### [√] 数据形状

---

![image-20221219162856215](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219162741543.png)

---

###### [√] 数据可视化

---

![image-20221219162922050](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219163205537.png)

---

###### [√] 数据预处理

---

resize + normalize

---

###### [√] 数据集封装

---

> alec：
>
> 数据集类继承Dataset类，类中有\_\_getitem\_\_方法和\-\-len\-\-方法，其中getitem方法，根据索引获取数据，然后对数据预处理，然后返回处理后的数据和标签

![image-20221219163205537](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219164238798.png)

---

#### [√] 模型构建

---

###### [√] LeNet-5

---

> alec：
>
> 随着网络的加深，虽然特征图长度越来越小，甚至变成1×1的，但是因为高层的一个像素（神经元）对应的输入图像的感受野非常大，所以 即使一个像素，也包含了大的特征。同时随着深度加深，通常特征通道数即特征图像个数会增加。最后通过全连接层将这些多个高级特征全连接用于分类等任务。
>
> 一开始，输入图像的三个通道，只是单纯的三个通道，但是在卷积网络中，每一层的多个通道都是对应的多种特征图。、
>
> ---
>
> > 全连接层对比卷积层的不足在于，全连接无法提取图像的局部不变性特征
>
> ---
>
> 卷积之后，先激活，然后再汇聚
>
> ---
>
> ![image-20221219164333869](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219164621216.png)
>
> 卷积层进入全连接之前，需要做一个reshape操作，因为卷积得到的是[B,C,H,W]形状的特征图，全连接需要输入一维列向量，因此需要将[B,C,H,W]转为[B,C×H×W]。

![image-20221219163725636](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219172424150.png)

![image-20221219164238798](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219164529451.png)

![image-20221219164430763](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219172519358.png)

---

###### [√] LeNet-5的参数量

---

![image-20221219164529451](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219173720075.png)

---

###### [√] LeNet-5的计算量

---

![image-20221219164621216](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219173345892.png)

![image-20221219164634943](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219174919075.png)

> alec：
>
> flops方法可以计算模型的计算量，就不用自己手动算了

---

###### [√] 模型运算速度对比

---

#### [√] 模型训练

---

###### [√] 模型训练

---

![image-20221219172306611](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219172458036.png)

---

#### [√] 模型训练与评价

---

###### [√] 训练过程可视化 && 模型评价

---

![image-20221219172424150](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219175218043.png)

![image-20221219172458036](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219180020784.png)





![image-20221219172519358](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219180509425.png)

---

## [√] 5.4 - 基于残差网络实现手写数字识别

---

#### [√] 残差网络

---

![image-20221219173345892](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219173844842.png)

> alec：
>
> 残差网络中，将目标函数分为了两部分：恒等函数 + 残差函数
>
> 残差的思想在Gradient Boosting也有

---

###### [√] 残差单元

---

![image-20221219173720075](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219180824283.png)

> alec：
>
> 较深的网络中，残差单元的结构变成了中间细、两头粗的沙漏结构

---

###### [√] 1×1卷积

---

![image-20221219173844842](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219180556815.png)

---

###### [√] ResNet18

---

![image-20221219174743636](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219143721941.png)

> alec：
>
> 第一种残差单元：通道数不变
>
> 第二种残差单元：通道数翻倍（在直连边通过1×1卷积调整通道数）
>
> 即特征图的数量不变或者翻倍
>
> ---
>
> 残差单元的结构：
>
> 卷积+BN+ReLU
>
> 卷积+BN
>
> (残差边 + 直连边)->ReLU
>
> ---
>
> 直连边 和 残差变 相加之后，再通过非线性激活函数
>
> ---
>
> BN，BatchNorm2D：
>
> - 根据当前批次数据按通道计算的均值和方差进行归一化



---

###### [√] ResNet18各模块

---

![image-20221219174919075](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219145412085.png)

![image-20221219175122875](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219164430763.png)

![image-20221219175218043](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219144138294.png)



---

###### [√] ResNet18的参数量和计算量

---

![image-20221219175400105](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219164634943.png)



![image-20221219175423093](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219172306611.png)

---

#### [√] 模型训练

---

###### [√] 没有残差连接的ResNet18

---



> alec：
>
> self.short表示的是直连边
>
> paddle.sumary()方法用来计算参数量

---

#### [√] 模型评价

---



![image-20221219180020784](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219175400105.png)

---

## [√] 5.5 - ResNet18完成图像分类任务

---

#### [√] 数据处理

---

###### [√] 数据集介绍

---

![image-20221219180356578](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219174743636.png)

---

###### [√] 数据读取

---

![image-20221219180509425](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219180648994.png)

---

###### [√] 数据可视化

---

![image-20221219180556815](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219180902611.png)

---

###### [√] 构建Dataset类

---

![image-20221219180648994](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219181000117.png)

---

#### [√] 模型构建与训练

---

###### [√] 模型构建

---

![image-20221219180824283](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219181022501.png)

---

###### [√] 模型训练

---

![image-20221219180902611](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219180356578.png)





---

#### [√] 训练结果

---

###### [√] 结果可视化 && 评价 && 预测

---

![image-20221219181000117](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219175423093.png)

![image-20221219181022501](https://raw.githubusercontent.com/alec-97/alec-s-images-cloud/master/img2/image-20221219175122875.png)

> alec：
>
> weight_decay用来L2正则化





