---
title: 1 - 课节1 绪论
categories:
  - 深度学习技术栈
  - 深度学习
  - 分支导航
  - 视频学习
  - 神经网络与深度学习 - 飞桨 - 复旦大学 - 邱锡鹏（NNDL蒲公英书）
  - 笔记
abbrlink: 2249908027
---



## 1 - 课节1: 绪论

### 1.0 - 绪论

![image-20221207170827279](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107424.png)

![image-20221207171145135](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107686.png)

![image-20221207171847495](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107687.png)

![image-20221207171854477](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107688.png)

![image-20221207171903791](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107689.png)

![image-20221207171958377](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107690.png)

![image-20221207172206926](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107691.png)

![image-20221207172316695](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107692.png)

---

### 1.1 - 人工智能

![image-20221207173118410](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107693.png)

![image-20221207173533968](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107694.png)

![image-20221207174108012](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107695.png)

---

### 1.2 - 如何开发人工智能系统

![image-20221207174718263](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107696.png)

![image-20221207204413823](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107697.png)

---

### 1.3 - 表示学习

![image-20221207204933064](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107698.png)

![image-20221207205211147](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107699.png)

![image-20221207205339195](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107700.png)

![image-20221207205748579](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107701.png)

![image-20221207210030232](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107702.png)

![image-20221207210139541](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107703.png)

![image-20221207210231829](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107704.png)![image-20221207210232055](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107705.png)

![image-20221207210342202](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107706.png)

![image-20221207210452441](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107707.png)

- 特征提取含有人工的过程，不能保证学习到的特征一定能帮助于分类
- 表示学习是将输入和输出直接串联到一起，希望学到的这种表示(特征)是对后面的这种分类是直接有帮助的，希望这种表示能够蕴含高层的语义特征。表示学习的难点在于没有明确的目标。它所有的信息都间接的来自于后面的分类器的效果。因此这种学习要和整个模型的预测效果一起学习，所谓的从输入到输出的端到端学习。

---

### 1.4 - 深度学习

![image-20221207215041274](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107708.png)

![image-20221207215210308](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107709.png)

- 深度学习和浅层学习的区别在于，不需要人为的去进行特征的提取，而是由计算机来自动的学习提取特征。浅层的学习的时候，比如芒果分类，需要人为的寻找出比如颜色、大小、品种、价格等特征，然后作为输入特征x，以及标签甜度y，来进行浅层的预测学习映射函数。而到了深度学习的这里，不需要人为的去设计特征，而是由计算机自动的去学习特征。深度学习 = 表示学习(特征学习)+浅层学习(预测、决策学习)。

深度学习和浅层学习相比，难点、也就是和浅层学习相比不同点是什么，核心是贡献度分配问题。

![image-20221207215751482](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107710.png)

- 即到底是哪个模块对最终的预测结果影响最大、即贡献最大。这就是贡献度分配问题。
- 无法直接推导出是哪个模块贡献度最大，就比如下棋，无法知道哪一步棋对最终的结果影响最大，只能是得到最后的结果之后，一步步的往前推演，才能知道哪一步对最终的胜局帮助最大。
- 在理想情况下可以通过强化学习来解决贡献度分配问题，但是在一般的学习中无法解决贡献度分配问题。一般情况下解决贡献度分配问题的很好的模型就是神经网络。

==端到端：==

端到端学习就是在整个过程中，中间是没有任何干预的。

==浅层学习：==

y = f(x)，即输入特征x和结果y，计算机自动来学习分类器映射函数f。在深度学习中，可能x这个特征也不是直接拿到的，这个也是需要计算机来自动的学习。



![image-20221207224308969](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107711.png)

---

### 1.5 - 神经网络

![image-20221207224430875](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107712.png)

单个神经元，通过树突接受来自其它神经元的刺激，当这种刺激积累到一定的程度，就会兴奋，如果没有达到这个阈值的话，就是抑制状态，即不产生信号。当产生兴奋的时候，通过轴突将信号传递给其它的神经元。

![image-20221207224729031](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107713.png)

==如何模拟人工神经元==

![image-20221207224901433](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107714.png)

x代表来自其它神经元的信息，即当前神经元接收的信号

w用来模拟不同神经元之间的连接强度

激活函数表示为阈值函数，也可以是上面的这种阈值函数。如果上面的接收的信号汇总起来越小，那么值越低、就不兴奋；汇总的信息量越大，那么会兴奋。模拟人类的神经元的兴奋与抑制。

![image-20221207225326740](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107715.png)

不同的神经网络的区别主要在于上面的三个方面的区别。

![image-20221207225434013](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107716.png)

前馈网络：信息是单向传递的

记忆网络：是有反馈边的

图网络：



![image-20221207225840718](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107717.png)

每一层都可以看做是特征的抽取器，整个的前馈网络的学习可以看成是端到端的学习。前面的可以看成是表示学习，后面的是浅层学习。

==神经网络是如何解决贡献度分配问题的额呢？==

核心是神经网络是连续可导的。

如何看x对y的影响是多大呢，可以在某个位置对x做一个扰动，看y的变动有多少，这样就能知道当前x的贡献度。从而知道当前x的贡献度。

如果当前的参数比较重要的话，那么对输入做一个扰动，那么输出的变化应该就很大，意味着贡献度很大。因此这样就能确定在每一个模块中的贡献度问题。当结果不好的时候就知道应该调哪些参数，因此神经网络比较完美的解决了贡献度分配问题。

![image-20221207230411453](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107718.png)

神经网络给深度学习提供了一种很好的解决贡献度问题的方法。



---

### 1.6 - 神经网络发展史

![image-20221207230704947](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107719.png)

![image-20221207230853446](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107720.png)

如何优化神经网络：反向传播算法

![image-20221207230956143](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107721.png)

![image-20221207231118538](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107722.png)

![image-20221207231238666](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202212212107723.png)

