---
title: 029 - 文章阅读笔记：【图像超分辨率重建】——HAN论文精读笔记
index_img: >-
  https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202301151818907.png
tags:
  - 超分辨率重建
  - 计算机视觉
  - 深度学习
  - 注意力机制
categories:
  - 深度学习技术栈
  - 超分辨率重建
  - 文章学习
abbrlink: 2820849598
date: 2023-01-15 16:16:24
---

> 转载自：
>
> 【√】[【图像超分辨率重建】——HAN论文精读笔记](https://blog.csdn.net/zency/article/details/128335691)
>
> 于 2022-12-16 16:38:19 发布

# 2020-Single Image Super-Resolution via a Holistic Attention Network(HAN)

---

## [√] 基本信息

---

> alec：
>
> - 信息性特征在单幅图像的超分辨率任务中起着至关重要的作用。通道注意力已被证明可以有效地保留每一层的信息丰富的特征。
> - 通道注意将每个卷积层作为一个单独的过程，而忽略了不同层之间的关联性。（通道注意力关注同一层中的不同通道之间的权重，而忽略了不同的卷积层之间的关联性）。
> - 本文提出了一个整体注意力网络。
> - 本文提出的整体注意力网络，关注三个方面的注意力，分别是通道、空间、层的注意力。

**作者：** Ben Niu; Weilei Wen; Wenqi Ren, Xiangde Zhang, Lianping Yang;Shuzhen Wang, Kaihao Zhang, Xiaochun Cao, and Haifeng Shen
**期刊：** ECCV2020
**引用：** *
**摘要：** 信息性特征在单幅图像的[超分辨率](https://so.csdn.net/so/search?q=超分辨率&spm=1001.2101.3001.7020)任务中起着至关重要的作用。通道注意力已被证明可以有效地保留每一层的信息丰富的特征。然而，通道注意将每个卷积层作为一个单独的过程，而忽略了不同层之间的关联性。为了解决这个问题，我们**提出了一个新的整体注意网络（HAN），它由一个层注意模块（LAM）和一个通道空间注意模块（CSAM）组成，用来模拟层、通道和位置之间的整体相互依赖关系**。特别是，拟议的**LAM通过考虑各层之间的相关性，自适应地强调层次特征。同时，CSAM学习每个通道的所有位置的条件，以选择性地捕获更多的信息特征**。广泛的实验表明，所提出的HAN与最先进的单幅图像超分辨率方法相比，表现得很好。





## [√] 1.简介

---

基于CNN的方法主要归功于两个方面
**非常深的层的网络**：有更大的接受域，具有能力来学习LR输入和HR对应之间的复杂映射关系
**残差学习**：SR网络的深度会越来越深，因为残差学习可以有效地缓解梯度消失和爆炸的问题

> alec：
>
> - 目前的方法忽略了中间层的特征相关性

- **目前超分存在的问题**：但是由于现有的大多数基于CNN的SR方法忽略了中间层的特征相关性，LR图像的**纹理细节往往在超分辨率的结果中被平滑化**。因此，在SR任务中，生成详细的纹理仍然是一个非艰巨的问题。虽然通过使用[通道注意力](https://so.csdn.net/so/search?q=通道注意力&spm=1001.2101.3001.7020)得到的结果保留了一些细节信息，但这些**基于通道注意力的方法在保留信息纹理和恢复自然细节方面很困难，因为它们平等地对待不同层的特征图，导致在重建的图像中损失了一些细节部分。**

- **RCAN存在的局限**：**不能对来自多尺度层的特征进行加权**。特别是来自浅层的长期信息很容易被削弱。尽管浅层特征可以通过跳过连接进行回收，但在长跳过连接后，它们与深层特征在各层中被同等对待，因此阻碍了CNN的表示能力。
- **本文对RCAN的改进**：我们考虑在层次上探索特征之间的相互关系，并提出了一个层注意模块（LAM）。另一方面，通道注意忽略了每个特征图中不同位置的重要性。因此，我们还提出了一个通道-空间注意模块（CSAM），以协同提高所提出的SR网络的识别能力。

> alec：
>
> - RACN，是残差通道注意力网络。主要关注通道注意力。

**本文的贡献**：

- **提出了一种新的超级分辨率算法**，名为整体注意力网络（HAN），它增强了超级分辨率的特征表征的表示能力。
- 我们引入了一个**层注意模块（LAM）**，通过考虑多尺度层的相关性来学习分层特征的权重。同时，我们提出了一个**通道-空间注意模块（CSAM**）来学习各层特征的通道和空间的相互依赖性。
- 所提出的两个注意力**模块通过对分层、通道和位置之间的信息特征进行建模，协同改善SR的结果**。广泛的实验表明，我们的算法与最先进的SISR方法相比表现良好。

## [√] 2.相关工作

---

- 基于深度学习的超分辨：SRCNN，DRCN，DRRN，LapSRN，EDSR，SRGAN，SRNTT等
- 注意力机制：RCAN、CBAM（其他领域）、MAM、SAN等

## [√] 3.HAN模型

---

#### [√] 3.1.网络结构

---

**网络结构：特征提取——LAM（层注意模块）——CSAM（通道注意模块）——重建模块**

- **HAN模型整体框架**

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202301151818907.png)

- LAM模块框架

学习不同深度特征之间的关系，提高特征表示能力

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202301151818908.png)

CSAM模块框架
提取强大的表示信息，以描述连续通道中的通道间和通道内的信息。

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202301151818909.png)



## [√] 4.实验

---

#### [√] 4.1.基本设置

---

- 训练集：DIV2K
- 测试集：Set5，Set14，B100，Urban100，Mega109
- 退化模型：BD模型和BI模型
- PSNR计算方式：YCbCr
- 使用RCAN的预训练模型初始化整体的注意力网络，Patch=64

#### [√] 4.2.LAM和CSAM的消融研究

---

仅使用LAM和仅使用CSAM相比于RCAN均有提升，且两个模块均使用提升更多。

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202301151818910.png)



#### [√] 4.3.不同数量的残差组的消融性研究

---

使用更少的RGs仍然比RCAN效果更好。

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202301151818911.png)



#### [√] 4.4.CSAM数量的消融研究

---

更多数量的CSAM会达到更优的效果

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202301151818912.png)



#### [√] 4.5.BI模型的结果

---



#### [√] 4.6.BD模型的结果

---

以上两部分的结果见原文

## [√] 5.结论

---

在本文中，我们**提出了一种用于单图像超分辨率的整体注意力网络，该网络使用自注意力机制自适应地学习不同深度、通道和位置之间的全局相关性**。具体来说，层关注模块（LAM）捕获分层层之间的长距离依赖关系。同时，频道空间注意模块（CSAM）将频道和上下文信息合并到每个层中。这两个注意力模块协同应用于多层次特征，然后可以捕获更多信息性特征。在基准数据集上的大量实验结果表明，所提出的模型在准确性和视觉质量方面优于最先进的SR算法。



> alec：
>
> - 本文的三种注意力机制，使用的是注意力机制中的自注意力机制。

## [√] 代码实现

---

https://github.com/wwlCape/HAN

## [√] 个人总结

---

- **本文是对RCAN注意力机制的继承和发展**