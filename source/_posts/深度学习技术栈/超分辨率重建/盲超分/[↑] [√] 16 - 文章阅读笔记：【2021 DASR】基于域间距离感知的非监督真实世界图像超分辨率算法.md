---
title: 文章阅读笔记：【2021 DASR】基于域间距离感知的非监督真实世界图像超分辨率算法
index_img: >-
  https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202302262240643.png
tags:
  - 盲超分
password: 972274
categories:
  - 深度学习技术栈
  - 超分辨率重建
  - 盲超分
abbrlink: 1625480038
date: 2023-02-26 17:47:02
---



> 原文链接：
>
> （1）【√】DASR：Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training - CSDN - 真实超分 - sr_super（[link](https://blog.csdn.net/sinat_34546154/article/details/112545582)）
>
> 于 2021-01-12 20:24:35 发布
>
> （2）【√】Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training - CSDN - 无监督超分——水组会 - coder-shen（[link](https://blog.csdn.net/qq_42500831/article/details/124866250)）
>
> 于 2022-05-19 20:33:20 发布
>
> （3）【√】Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training - CSDN - shanjw21（[link](https://blog.csdn.net/azhibihuamulan/article/details/124398498?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167758882916782428654495%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167758882916782428654495&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-124398498-null-null.142^v73^control_1,201^v4^add_ask,239^v2^insert_chatgpt&utm_term=Unsupervised%20Real-world%20Image%20Super%20Resolution%20via%20Domain-distance%20Aware%20Training&spm=1018.2226.3001.4187)）
>
> 已于 2022-04-25 10:11:04 修改
>
> ps：本文为依据个人日常阅读习惯，在原文的基础上记录阅读进度、记录个人想法和收获所写，关于原文一切内容的著作权全部归原作者所有。







#  [√] 文章信息

---

论文标题【2021 DASR】Unsupervised real-world image super-resolution via domain-distance aware training

中文标题：基于域间距离感知的非监督真实世界图像超分辨率算法

论文链接：https://arxiv.org/abs/2004.01178

论文代码：https://github.com/ShuhangGu/DASR

论文发表：CVPR 2021



# [√] 文章1

---

> 总结：
>
> 【本文思想】
>
> - 本文有两个网络：一个网络是DSN网络，负责生成自然的LR；一个网络是SRN网络，负责将自然的LR超分辨率。
> - 在DSN中，会有三种类型的LR图像，分别是bicubic的LR、DSN生成的LR、自然LR。其中DSN生成的LR和bicubic的LR之间计算重建损失（像素损失）和感知损失（特征图的像素损失），从而使得内容保持一致；其中DSN生成的LR和自然图像LR之间的在高频空间计算对抗损失，从而使得二者的域保持一致。（其中提取高频信息是利用的小波变换。）
> - 其中高频空间计算对抗损失的时候，使用Patch-GAN作为判别器，得到了patch-level dense domain distance map，这个域间距map对后续的SRN过程有用。
> - 通过上面的这种方式，能够上自然LR图像生成网络生成的图像和域和自然图像的域尽可能的接近。同时经过这种训练，能够将判别是否是自然图像的能力赋予PatchGAN判别器，将这种相关参数渗透到判别器的参数中。这个参数可以在后续的超分模型中起到帮助，帮助模型在超分的同时更好的将自然LR图像中的自然降质因子给去除掉。
>
> 【本文贡献】
>
> - 文章提出了一种 domain-distance aware super-resolution (DASR) 方法，通过domain-gap aware training和 domain-distance weighted supervision strategies来解决训练数据（合成的LR图像）和测试数据（真实的LR图像）的域偏差情况。
> - 训练过程：
>
> ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416025.png)
>
> 
>
> 【网络结构】
>
> ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416027.png)
>
> ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416028.png)
>
> ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416029.png)
>
> - 这里有源域和目标域。这里的目标域指的是自然图像的域。其中对于源域采用有监督的方式进行训练，因为对于源域来讲数据是成对的；其中HR是本身的HR，LR是降质网络生成的自然LR。而对于目标域来讲，因为本身自然的LR图像，不像生成的自然LR图像，本身自然的LR图像没有对应的HR，因此在SR之后，只能通过高通滤波+对抗损失和HR图像计算损失。
>
> 【可以用于自己论文的话】
>
> 【可以用于自己论文的idea】
>
> - 本文考虑了生成的自然LR图像和真实的自然LR图像之间的域偏差，因此这种考虑范围内的效果可解释性很好。
> - 本文在将自然降质因子嵌入到LR图像的时候，是使用的小波变换提取高频信息来通过判别器判别。那么这里就是假设自然降质因子是高频的一种成分。但是对于降质因子来说是否是高频的不确定，因为这里通过高通滤波器是否会影响性能呢？
> - 本文有两个网络：一个网络是DSN网络，负责生成自然的LR；一个网络是SRN网络，负责将自然的LR超分辨率。在DSN中，会有三种类型的LR图像，分别是bicubic的LR、DSN生成的LR、自然LR。其中DSN生成的LR和bicubic的LR之间计算重建损失（像素损失）和感知损失（特征图的像素损失），从而使得内容保持一致；其中DSN生成的LR和自然图像LR之间的在高频空间计算对抗损失，从而使得二者的域保持一致。（其中提取高频信息是利用的小波变换。）其中高频空间计算对抗损失的时候，使用Patch-GAN作为判别器，得到了patch-level dense domain distance map，这个域间距map对后续的SRN过程有用。
> - 通过上面的这种方式，能够上自然LR图像生成网络生成的图像和域和自然图像的域尽可能的接近。同时经过这种训练，能够将判别是否是自然图像的能力赋予PatchGAN判别器，将这种相关参数渗透到判别器的参数中。这个参数可以在后续的超分模型中起到帮助，帮助模型在超分的同时更好的将自然LR图像中的自然降质因子给去除掉。
> - 本文的网络是具有创意的网络，且也是对于训练方式做了创新，对于网路结构的细节没有很多的改动。因此自己的模型也可以考虑使用这种模型。
> - 这里对伪造的LR图像和自然的LR图像都做了超分，从而使得超分网络的超分+去降质能力更强。（多数的盲超分都是得到伪造的LR，然后进行配对的超分训练，没有考虑对自然的LR也进行训练。这里加入了对自然的LR也进行超分，是一种不错的idea）是一个很好的创新训练方式。其中因为自然LR图像没有对应的HR图像，因此在超分的时候，自然LR图像和非配对的HR图像之间的高频成分计算对抗损失。
> - \- Domain-gap aware training，域分界线感知的训练是对于目标域的高频对抗损失训练来说的，好让超分模型更好的弄清楚目标域和源域之间的界限，从而更好的在目标进行超分。
> - \- Domain-distance weighted supervision则是为了在图像内容领域，即在目标域内更好的让SR和HR靠拢。
> - \- 个人理解：Domain-gap aware training先让超分模型找到目标域这个大的特征空间，然后再在这个目标域的基础上进行图像内容方向的超分，从而既能去除自然的噪声、同时又能得到清晰的高分辨率图像。
>
> 【问题记录】
>
> 【零碎点】
>
> - Patch-GAN：在普通的GAN学习中，判别器D网络的输出是一个标量，介于0~1之间，代表是真实图片的概率。而patchGAN则是输出是NxN的矩阵X，每一个元素x[i][j]表示一个patch，对应于图像的一个感受野，最后取各个patch部位的均值来表示最后总的来看是真实图片的概率。

## [√] 引言

---

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416030.png)

[PDF] http://xxx.itp.ac.cn/pdf/2004.01178.pdf

[CODE] https://github.com/ShuhangGu/DASR

CVPR 2021

## [√] Motivation

---

- 现在目前的超分方法都是在合成的LR图像上进行训练的，但是合成LR图像（如，双三次下采样）和真实LR图像域不一致，所以导致最终的超分模型在真实LR图像上的结果不理想。
- 目前的主流解决方法是根据给定的真实LR图像数据集，训练一个降质网络，让合成的LR图像的域与真实LR图像保持一致，以此形成LR-HR对来训练SR网络。
- 但是通过这种方式得到的合成LR图像的域与真实LR图像依然存在域偏差domain gap，下面这幅图说明了这个问题，它把bicubic、FSSR、DASR（文章提出的网络 ）得到的LR图像输入到一个判别器中进行训练，把结果以直方图的形式输出，从左图中可以看出bicubic、FSSR、DASR得到的LR图像它们之间存在域偏差，这种偏差会影响SR网络在真实LR图像上的超分效果。

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416031.png)

文章提出了一种 domain-distance aware super-resolution (DASR) 方法，通过domain-gap aware training和 domain-distance weighted supervision strategies来解决训练数据（合成的LR图像）和测试数据（真实的LR图像）的域偏差情况。

## [√] Method：DASR for Unsupervised Real-World Image SR

---

#### [√] 1 Overview

---

![image-20230226180555296](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416032.png)

> 过程分为两个阶段：
> ①通过一个下采样网络（ downsampling network DSN)，从HR图像中生成与真实LR图像域一样的合成LR图像y g y^gyg，形成LR-HR对。
> ②将得到的LR-HR 对进行训练一个SR网络（SRN)，在训练SRN过程中，DASR会将y g y^gyg和y r y^ryr之间的域偏差考虑进来，并且使用domain-gap aware training 和 domain-distance weighted supervision strategies来充分利用真实LR图像信息进行训练。
>
> ![image-20230226180818959](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416033.png)

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416034.png)

#### [√] 2 Training of Down-Sampling Network

---

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416035.png)

> 这里说明如何得到合成的LR-HR对，将HR图像作为网络输入，经过23的residual blocks，得到输出y g y^gyg。y b y^byb通过双三下采样得到，为了让y g y^gyg和y b y^byb在内容上保持一致，通过重建损失和感知损失来约束网络：
>
> ![image-20230226211517119](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416036.png)

> 为了让y g y^gyg和y r y^ryr的域保持一致，使用对抗损失，但是只在高频空间上进行。文章使用Haar 小波变换来提取高频信息，将小波变化分为得到的四个子带LH，LH，HL和HH，将高频子带LH，HL和HH进行堆叠来作为判别器的输入，haar小波变化还利用了方向信息来更好的表征图像细节。
>
> ![image-20230226211701456](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416037.png)

对抗损失可以让网络忽略与SR任务无关的低频信息，同时能够降低网络训练的难度。判别器使用的是一个Patch-GAN策略，通过它得到patch-level dense domain distance map对后续的SRN过程有用。

> Patch-GAN
> 在普通的GAN学习中，判别器D网络的输出是一个标量，介于0~1之间，代表是真实图片的概率。而patchGAN则是输出是NxN的矩阵X，每一个元素x[i][j]表示一个patch，对应于图像的一个感受野，最后取各个patch部位的均值来表示最后总的来看是真实图片的概率。

总体损失：

![image-20230226212515752](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416038.png)

其中在实验中α=0.01，β=1，γ=0.0005，HR图像块大小为192 x 192



> alec：
>
> - 通过上面的这种方式，能够上自然LR图像生成网络生成的图像和域和自然图像的域尽可能的接近。同时经过这种训练，能够将判别是否是自然图像的能力赋予PatchGAN判别器，将这种相关参数渗透到判别器的参数中。这个参数可以在后续的超分模型中起到帮助，帮助模型在超分的同时更好的将自然LR图像中的自然降质因子给去除掉。

#### [√] 3 Domain distance aware training of Super-Resolution Network

---

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416039.png)

> 采用Domain-gap aware training和Domain-distance weighted supervision两种策略来解决从DSN得到的y g y^gyg和y r y^ryr之间的域偏差问题，SRN受两个域约束，针对源域采用的是带标签的数据集y g , x r {y^g, x^r}yg,xr，针对目标域采用的无标签的真实LR图像数据集。
>
> ![image-20230226213227127](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416040.png)

1）**Domain-gap aware training**：对源域和目标域采用不同的损失函数，对于有标签的源域，采用一种有监督的方法进行训练网络，对于目标域，使用对抗损失在高频信息空间上使输出。![image-20230226214714533](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416041.png)

和HR图像x r x^rxr的分布对齐，损失函数：

![image-20230226214734944](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416042.png)

> 2）**Domain-distance weighted supervision**：由于来自不同域的图像之间的差异仅表现在低级特征上，因此生成图像的每一区域与真实图像domain具有不同的domain距离。当用源域数据y g , x r {y^g, x^r}yg,xr来训练目标域SRN时，应根据不同区域到目标域的距离赋予不同重要性，而DSN得到的patch-level dense domain distance map可以用来表示它们之间的距离，根据这个距离我们给不同区域赋予不同的权重：
>
> ![image-20230226221420869](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416043.png)

![image-20230226221453587](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416044.png)

![image-20230226223849307](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416045.png)



> alec：
>
> - 这里对伪造的LR图像和自然的LR图像都做了超分，从而使得超分网络的超分+去降质能力更强。（多数的盲超分都是得到伪造的LR，然后进行配对的超分训练，没有考虑对自然的LR也进行训练。这里加入了对自然的LR也进行超分，是一种不错的idea）是一个很好的创新训练方式。其中因为自然LR图像没有对应的HR图像，因此在超分的时候，自然LR图像和非配对的HR图像之间的高频成分计算对抗损失。
> - 这里有源域和目标域。这里的目标域指的是自然图像的域。其中对于源域采用有监督的方式进行训练，因为对于源域来讲数据是成对的；其中HR是本身的HR，LR是降质网络生成的自然LR。而对于目标域来讲，因为本身自然的LR图像，不像生成的自然LR图像，本身自然的LR图像没有对应的HR，因此在SR之后，只能通过高通滤波+对抗损失和HR图像计算损失。
> - Domain-gap aware training，域分界线感知的训练是对于目标域的高频对抗损失训练来说的，好让超分模型更好的弄清楚目标域和源域之间的界限，从而更好的在目标进行超分。
> - Domain-distance weighted supervision则是为了在图像内容领域，即在目标域内更好的让SR和HR靠拢。
> - 个人理解：Domain-gap aware training先让超分模型找到目标域这个大的特征空间，然后再在这个目标域的基础上进行图像内容方向的超分，从而既能去除自然的噪声、同时又能得到清晰的高分辨率图像。



# [√] 文章2

---

> 总结：
>
> 【本文思想】
>
> 【本文贡献】
>
> 【网络结构】
>
> 【可以用于自己论文的话】
>
> - 一般来说，用于训练的LR和真实的LR之间存在domain gap
> - 给定一组真实世界包含模糊、伪影的图像LR，以及一组HR，寻找一种方法，在没有配对数据的情况下，能够将LR重建出SR，使得SR更加接近于HR domain
>
> 【可以用于自己论文的idea】
>
> 【问题记录】
>
> 【零碎点】
>
> - 一般来说，用于训练的LR和真实的LR之间存在domain gap
> - 盲超分的目的是在没有配对数据的情况下，将LR重建出SR，使得SR更加接近于HR domain
> - DSN中对抗损失只在高频计算的原因：unpaired数据如果用L_{adv}容易产生图像伪影，并且可能难以收敛，因此在DSN中仅仅只将高频信息输入判别器，因为图像的噪声退化主要集中在高频信息
> - 在训练阶段，DSN内部的Discriminator会输出一个Domain Distance Map，map上的值表示对图像各个patch是real还是fake的判定，将这个判定作为domain gap的度量，用于后续SR网络的训练
> - 在训练阶段，DSN内部的Discriminator会输出一个Domain Distance Map，map上的值表示对图像各个patch是real还是fake的判定，将这个判定作为domain gap的度量，用于后续SR网络的训练
>
> ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416046.png)
>
> - 注意在SR中，Domain Distance Map是对图像的各个patch的loss进行的加权：在source domain中，在L1损失的基础上，使用Domain Distance Map对图像各个patch的loss进行重新加权，使得domain gap更小的patch的L1 loss更大，让网络更关注于domain gap更小的patch，同时减小domain gap大的patch对网络训练的扰动
>
> ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416047.png)
>
> - 在该框架中，可以保持LR->HR图像内容的一致性，并学到real world LR->HR的映射关系，进一步减小domain gap带来的影响



## [√] 引文

---

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416048.png)

Bicubic的方法无法对真实场景下的退化进行模拟，真实图像往往包含噪声以及运动伪影等，因此用于训练模型的LR与真实世界图像之间存在domain gap

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416049.png)



## [√] 盲超分问题的设定

---

**盲超分问题的设定**：给定一组真实世界包含模糊、伪影的图像LR，以及一组HR，寻找一种方法，在没有配对数据的情况下，能够将LR重建出SR，使得SR更加接近于HR domain

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416050.png)

一般分为三类：

1.直接拍摄获得成对数据

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416051.png)

调整相机的焦距，拍摄LR、HR图像，获得成对的训练数据
缺点：费时费力、成本高

2.假设真实世界LR和HR之间的退化关系可以被特定模糊核以及下采样模拟
![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416052.png)
用real-world LR生成模糊核，用于下采样HR，即可得到接近于real-world的LR
缺点：退化方式较为复杂时，模糊核难以模拟

3.无监督训练方式
![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416053.png)
这种方式不依赖于任何先验假设和退化模型，首先训练一个退化网络，用于将HR下采样到LR domain，从而获得LR-HR对，然后用成对数据训练超分网络
缺点：生成的LR与real-world LR存在domain gap





## [√] 提出的新超分框架

---

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416054.png)

首先训练基于GAN的下采样网络DSN，将HR下采样到real-world domain，同时生成Domain Distance Map

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416055.png)

unpaired数据如果用L_{adv}容易产生图像伪影，并且可能难以收敛，因此在DSN中仅仅只将高频信息输入判别器，因为图像的噪声退化主要集中在高频信息

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416056.png)

为了避免冗余信息的影响，让判别器判别的特征更加明确，作者采用高频判别的方式训练

在训练阶段，DSN内部的Discriminator会输出一个Domain Distance Map，map上的值表示对图像各个patch是real还是fake的判定，将这个判定作为domain gap的度量，用于后续SR网络的训练

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416057.png)

生成了LR-HR pair（生成的fake LR和GT）后，作者将数据分为两类（source domain和target domain），进行SR网络的训练

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416058.png)

在source domain中，在L1损失的基础上，使用Domain Distance Map对图像各个patch的loss进行重新加权，使得domain gap更小的patch的L1 loss更大，让网络更关注于domain gap更小的patch，同时减小domain gap大的patch对网络训练的扰动

在target domain中，在高频域使用没有GT的real world图像的L a d v L_{adv}Ladv，从而缩小生成的图像domain和HR domain之间的差距

在该框架中，可以保持LR->HR图像内容的一致性，并学到real world LR->HR的映射关系，进一步减小domain gap带来的影响



## [√] 实验部分

---

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416059.png)

给定DIV2K中的800张HR图片（target domain），以及2650张未知退化的LR作为source domain，目标是将未知退化的LR作为source domain，重建出接近target domain的SR图像

#### [√] 消融实验

---

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416060.png)

1. 输入LR
2. 输入HR用DSN下采样，并且不分离高低频信息
3. 输入HR用DSN下采样，并且用高斯核分离高低频信息
4. 输入HR用DSN下采样，并且用wavelet分离高低频信息

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416061.png)

作者采用的wavelet得到的PSNR为26.007

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416062.png)



# [√] 文章3

---

> 总结：
>
> 【本文思想】
>
> - 在这篇文章中，我们使用域自适应来改善真实数据上的超分性能，作者是第一个应用域适应来提升低分辨率图像增强的。
>
> 
>
> 【本文贡献】
>
> ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416063.png)
>
> 1. 域间隙感知训练策略
>
> 1. 1. 域间隙感知训练是我们模型成功的关键。
>
> 1. 域距离加权监督策略
> 2. 更好的下采样网络用于合成LR数据
>
> 1. 1. 直接对HR处理得到混合自然噪声的LR，而不是对下采样的LR处理得到混合自然噪声的LR
>
> 1. 高频提取使用小波变换来提取
> 2. 使用patchGAN作为对抗损失
>
> 【网络结构】
>
> 【可以用于自己论文的话】
>
> - 由于双三次插值方法得到的LR数据不代表自然场景下真实的数据，因为这是一种伪配对数据。伪配对数据得到训练得到的超分模型泛化性能很差，无法适用于自然场景下含有丰富降质因素的LR图像。由于图片分辨率转换本身就是一个具有挑战性的任务，这样做的方法使得超分性能受到生成图片LR与真实的LR之间的域间隙（domain gap）的限制。
> - 域差距感知 + 域距离加权监督训练：训练数据(例如y\^g)和测试数据(例如y\^r)之间的域差距通过我们的域差距感( **domain-gap aware training **)知训练和域距离加权监督策略( **domain-distance weighted supervision strategies**)来解决。
> - 为了避免在输入和输出之间改变图像大小，现有的方法采用双三次下采样操作作为预处理步骤Frequency Separation for Real-World Super-Resolution。然而，尽管降低了转换难度预处理下采样操作会移除生成真实低分辨率图片的必要的信息。DSN则使用高分辨率图片作为输入，通过网络直接捕捉整个退化过程。这样不会在双三次下采样中损失信息。
> - 然而y\^g和y\^r之间的域间隙仍然存在。当对合成数据进行训练的SR网络应用于超分辨率真实的LR图像时，训练数据和测试数据之间的领域差距将导致性能下降。
> - 鉴别器的输出代表输入来自目标域的概率。因此，鉴别器输出越大，输入来自目标真实世界LR域的可能性就越高，到目标域的距离就越小。我们直接利用判别器的输出来加权每个局部区域的重要性。
> - 由于GAN方法侧重于恢复图像的感知质量，因此学习感知图像块相似度(LPIPS)和平均意见得分(MOS)被用作评价不同方法的主要指标。
> - 除了感知指标外，还使用峰值信噪比(PSNR)和结构相似指数(SSIM)作为参考的额外定量指标。
>
> 【可以用于自己论文的idea】
>
> - 本文的DSN和SRN中加入了对抗损失，不就是DegradationGAN中的对抗损失吗，只不过是将两个GAN网络分开了。创新性的地方在于，将自然图像也进行了超分，然后和HR进行高频部分的对抗损失计算，并且将DSN的判别器中的patch grade放到了SRN的像素损失中进行加权。那么是否可以将SRN中的判别器中的patch grade也放到DSN中的像素损失用于加权？
>
> 【问题记录】
>
> 【零碎点】
>
> - 由于双三次插值方法得到的LR数据不代表自然场景下真实的数据，因为这是一种伪配对数据。伪配对数据得到训练得到的超分模型泛化性能很差，无法适用于自然场景下含有丰富降质因素的LR图像。由于图片分辨率转换本身就是一个具有挑战性的任务，这样做的方法使得超分性能受到生成图片LR与真实的LR之间的域间隙（domain gap）的限制。
> - 训练数据(例如y\^g)和测试数据(例如y\^r)之间的域差距通过我们的域差距感( **domain-gap aware training **)知训练和域距离加权监督策略( **domain-distance weighted supervision strategies**)来解决。
> - 只在高频部分计算对抗损失，是来自于FSSR的思想。但是本文改变了高频滤波器，将高频滤波器改为哈尔小波变换滤波器。
> - 鉴别器的输出代表输入来自目标域的概率。因此，鉴别器输出越大，输入来自目标真实世界LR域的可能性就越高，到目标域的距离就越小。我们直接利用判别器的输出来加权每个局部区域的重要性。
> - 我们的适配策略适用于不同的网络架构。在本文中，我们直接采用ESRGAN 中使用的体系结构作为我们的SRN。
> - 由于GAN方法侧重于恢复图像的感知质量，因此学习感知图像块相似度(LPIPS)和平均意见得分(MOS)被用作评价不同方法的主要指标。
> - 除了感知指标外，还使用峰值信噪比(PSNR)和结构相似指数(SSIM)作为参考的额外定量指标。
> - 在该表中，HR/双三次LR表示不同下采样网络所使用的各自的输入。而高斯模糊频率分离(GBFS)、小波频率分离(WFS)和RGB表示模型在不同的空间进行对抗性训练：GBFS使用原始图像和高斯模糊图像之间的残差来提取高频分量，我们的WFS方法采用小波变换来提取高频分量，RGB意味着我们直接在RGB图像上引入GAN损耗。
> - 本文的DSN和SRN中加入了对抗损失，不就是DegradationGAN中的对抗损失吗，只不过是将两个GAN网络分开了。创新性的地方在于，将自然图像也进行了超分，然后和HR进行高频部分的对抗损失计算，并且将DSN的判别器中的patch grade放到了SRN的像素损失中进行加权。那么是否可以将SRN中的判别器中的patch grade也放到DSN中的像素损失用于加权？
> - 在我们的实验中，我们使用佳能相机收集的200张LR图像作为我们的真实LR图像，并使用DIV2K中的800张HR图像作为我们的HR图像。 我们用相同的数据训练我们的DASR模型以及FSSR和CinCGAN模型。经过无监督训练后，我们使用我们的模型在由100个LR-HR对组成的RealSR的验证集中对LR图像进行超分辨。



## [√] 0 Abstract

---

- 生词：off-the-shelf(现成的) synthetic(合成的) corresponding to(对应于) bring forward(提出) rational(合理，理性) validated（通过验证）consistently（始终如一的）realistic（逼真的）

> - 现有的方法理念在于增强未配对数据。首先从真实世界中的高分辨率图片（x r x^rxr）中生成低分辨率的图片(y g y^gyg)，对应的真实世界中的低分辨率图片(y r y^ryr)然后再用监督学习的方式训练pseudo pairs(伪配对)数据 {y g y^gyg,x r x^rxr} 。由于图片分辨率转换本身就是一个具有挑战性的任务，这样做的方法使得超分性能受到生成图片LR与真实的LR之间的域间隙（domain gap）的限制。
>
> ![image-20230228223723292](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416064.png)

- 提出了基于域距离感知的无监督真实图像超分辨率方法。(domain-distance aware super-resolution，DASR)。

- 训练数据(例如y\^g)和测试数据(例如y\^r)之间的域差距通过我们的域差距感( **domain-gap aware training **)知训练和域距离加权监督策略( **domain-distance weighted supervision strategies**)来解决。

- Domain-gap aware training从目标域真实数据中得到好处，Domain- distance weighted supervision 提出了更合理的使用标记源数据的方法。
- 作者认为自己的方法在合成的和真实数据库中得到了验证，DASR结果始终超过state-of-art非监督模型，产生 的图片纹理更逼真自然。



## [√] 1 Introduction

---

- 补充：[感知损失](https://www.jianshu.com/p/58fd418fcabf)：它是将真实图片卷积得到的feature与生成图片卷积得到的feature作比较，使得高层信息（内容和全局结构）接近，也就是感知的意思。

- 生词：**perceptual losses** [感知损失](https://so.csdn.net/so/search?q=感知损失&spm=1001.2101.3001.7020)。the poor generalization capacity 泛化能力差 pursuit 追求 laborious 复杂的 perspective视角 predetermined synthetic data 预定合成数据 parameterized degradation model 参数化退化模型 sensor noise传感器噪音 compression artifacts 压缩伪影 histogram直方图 leverage 利用，发挥作用。 an advanced exploitation of… 更进一步开发… superiority 优势

- discriminatively trained SR networks泛化能力差限制了其在真实场景中的应用。当应用于超分辨率真实图像时，在模拟数据集上训练的SR网络通常会导致SR结果中出现奇怪的伪影。
- 提升训练模型泛化率以使得在一个数据类别上训练的模型可以应用在其他问题上，一些方法认为HR与LR满足一种参数化退化关系，从算法视角提出了一些方法。这些方法提升了模型训练的泛化能力，但固定退化假设极大地限制了它们在真实数据上的性能，而真实数据往往受到复杂的传感器噪声和压缩伪影的影响。
- 如今，不基于参数退化模型假设而利用非配对的训练数据的非监督超分算法而利用非配对的训练数据的被提出。但是这些算法忽略了下采样的真实低分辨率图像与真实世界中低分辨率图像之间的域距离，尽管这些算法使用伪配对得到真实世界中低质量图像域的一些特点，获得了比较好的结果但是仍存在域距离。

- 不同于使用伪配对进行无监督学习的超分方法，我们考虑了Y\^g与Y\^r之间的域距离，在Domain adaptation setting下解决了超分存在的问题，通过domain-gap aware training (域距离感知训练)和 domain-distance weighted supervision(域距离加权监督策略)解决domain gap问题。

![image-20230228224707022](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416065.png)

- 作者的工作总结：
    - 提出DASR网络模型来解决真实世界SR问题。通过提出域距离感知训练和域距离加权监督策略，解决了生成的低质量图片与真实图片之间域距离问题。
    - 作者设置了 ablation studies （消融实验）来分析验证自己的方法的优势。





## [√] 2 Related Works

---

#### [√] 2.1 Single Image Super-Resolution with CNNs

---

- 生词：dominate 占据主导地位 pioneer work 开拓者工作 venture冒险，投机。 a surge of 一股激增的。perceptual loss（[感知损失](https://zhuanlan.zhihu.com/p/24720434)) manifold 流形 criterion 判据 aforementioned 上述的 simulated datasets 模拟数据集 blur kernel 模糊核 subsequent 后继 explicitly明确的说。 be capable of 有能力，可以。 generalizing 推广. be consist with 与…一致 deteriorate 恶化 Discrepancy差异

- 本段主要介绍了CNN网络在超分领域的发展，一些架构、损失函数设计以及不同训练标准（training criterions）的提出例如提出了基于感知驱动的感知损失函数改善感知质量结果。提高了超分的质量。

- 一些工作假设LR与HR图像退化模型可以通过未知的模糊核和随后的下采样操作来表征。这些盲SR在测试时显式地估计未知模糊核，并将估计的核作为核自适应超分网络的输入变量来满足不同的退化超参数。还有一些工作尝试使用测试图片信息在测试阶段训练或微调超分网络。然而这些工作都基于未知图像退化假说，最近的研究考虑非监督设定来代替退化假设。[一篇介绍2020年以前的超分工作的博客](https://blog.csdn.net/weixin_43692612/article/details/105763868)。



#### [√] 2.2 Domain Adaptation(领域自适应)

---

- 生词：deploy 部署
- 领域自适应的目的是利用已标记的源域来学习在未标记的目标域上表现良好的模型。[域适应](https://zhuanlan.zhihu.com/p/272508224) [简介](https://zhuanlan.zhihu.com/p/436487740)(核心思想：把Source 和 Target 上的数据，都投影到某一个共同的空间上 (Space)。在这个空间上Source 和 Target的数据差异会变小，就可以当成同一个数据集了，我们就能用各种分类器在这个空间上进行训练了。)。早期领域自适应在计算机视觉领域的研究重点是解决高层分类任务中的领域偏差问题,而最近，领域自适应也被用于更具挑战性的密集估计任务，如语义切分.在适当的自适应策略下，在合成数据集上训练的模型取得了与用真实标记数据训练的模型相当的性能。**在这篇文章中，我们使用域自适应来改善真实数据上的超分性能，作者是第一个应用域适应来提升低分辨率图像增强的。**



## [√] 3 Method

---

### [√] A - DASR for Unsupervised Real-World Image SR

---

#### [√] 3.1 方法概述

---

- 生词：simultaneously 同时 In contrast to 与之形成鲜明对比的是。adopt 采用

> 文章研究非监督真实世界图像超分问题。给定一系列真实世界低分辨率图片 Y r = ( y i r ) i = 1 , . . . M Y^r = {(y_i^r)}_{i = 1,...M}Yr=(yir)i=1,...M和一些未配对的高分辨率图片 X r = ( x i r ) i = 1 , . . . M X^r = {(x_i^r)}_{i = 1,...M}Xr=(xir)i=1,...M 。**我们的目标是学习一个SR网络(SRN)来扩大低分辨率图片LR的分辨率，同时确保高分辨率图片HR估计在真实的HR分布中。**
>
> ![image-20230228230245370](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416066.png)

> - 首先，我们训练一个下采样网络(DSN)来从HR图像生成真实的LR域中的LR图像： y i g = D S N ( x i r ) y_i^g = DSN(x_i^r)yig=DSN(xir) ，然后使用生成的LR-HR对 ( y i g , x i r ) i = 1 , . . . M {(y_i^g,x_i^r)}_{i = 1,...M}(yig,xir)i=1,...M 来训练SRN（超分网络）。与之前直接使用伪配对以监督学习方法训练SRN不同，DASR考虑 y g 与 y r y^g与 y^ryg与yr 域偏置，采用域间隙感知训练和域间距加权监督策略充分利用真实世界的LR图像以及生成的对。
>
> ![image-20230228230335427](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416067.png)

![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416068.png)



#### [√] 3.2 Training of Down-Sampling Network(通过从未配对的数据生成合成LR-HR对来训练下采样网络模型DSN)

---

- 生词：Despite 尽管 capture 俘获 spatial 空间的 resolution 分辨率 project 投影. content 内容. consistent 始终如一. Bicubic downsampled 双三次下采样。feature extractor 特征抽取器 denote表示 impose 强加 concretely 具体来说 sub-bands 子波段 wavelet-based 基于小波的 decompose 分解 symmetrical form 对称形式 impose 引入 a valid receptive field 有效的接受域. stabilize 稳定 halve减半

- Network architecture:
    - 为了避免在输入和输出之间改变图像大小，现有的方法采用双三次下采样操作作为预处理步骤[**Frequency Separation for Real-World Super-Resolution**](https://readpaper.com/pdf-annotate/note?noteId=677868756016455680&pdfId=4556052217019244545)。然而，尽管降低了转换难度预处理下采样操作会移除生成真实低分辨率图片的必要的信息。DSN则使用高分辨率图片作为输入，通过网络直接捕捉整个退化过程。这样不会在双三次下采样中损失信息。
    - DSN利用23个残差块从HR图像中提取信息，每个残差块包含两个卷积层(核大小为3×3，通道数为64)和其间的REU激活函数。然后，采用双线性调整算子和两层卷积层来降低特征的空间分辨率，并将特征投影回图像域。

![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416069.png)

Losses:

> - 为了保持生成的低分辨率图片与输入高分辨率图片内容上一致，使用内容损失函数 L c o n L_{con}Lcon 与感知损失函数 L p e r L_{per}Lper 来约束生成的低分辨率图片 LR 即 y i g = D S N ( x i r ) y_i ^ g = DSN(x_i^r)yig=DSN(xir) 和双三次下采样高分辨率图片 y i b y_i^byib :
>
> ![image-20230228230829774](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416070.png)

> 其中 y i b = β ( x i r ) y_i^b = \beta(x_i^r)yib=β(xir) 是对高分辨率图片进行双三次下采样得到的结果， ϕ ( . ) \phi(.)ϕ(.) 表示 VGG特征提取器。我们遵循[ESRGAN](https://zhuanlan.zhihu.com/p/156505590)[还有](https://www.cnblogs.com/carsonzhu/p/10967369.html)从卷积层5_3计算VGG-19特征的知觉损失。为了达到领域转换的目的，我们对图像事例 y g y^gyg 与 y r y^ryr强加了对抗损失。我们采用了FSSR的思想即只在高频率空间强加对抗损失。但是我们使用[Haar wavelet transform](https://blog.csdn.net/baidu_27643275/article/details/84826773)（哈尔小波变换）来提取更具信息量大高频成分。具体来说，使用哈尔小波变换分解为四个子波段 LL,LH,HL,HH。堆叠LH,HL,HH部分作为鉴别器的输入，与FSSR中使用的高频抽取器相比，我们的基于小波的抽取器还利用了方向信息来更好地表征图像细节。对生成器的 GAN loss 定义为:
>
> ![image-20230228231050301](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416071.png)

![image-20230228231103086](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416072.png)

其中 H w a v e l e t ( . ) H_{wavelet}(.)Hwavelet(.)表示使用哈尔小波变换提取LH,HL,HH子波段并将这三个变量连接起来。在高频域引入对抗性损失使我们能够忽略与SR任务不太相关的低频内容，而更多地关注图像细节。此外，在低维空间进行对抗性训练也降低了GAN训练的难度。使用与[CycleGAN](https://www.jianshu.com/p/64bf39804c80) [还有](https://blog.csdn.net/omnispace/article/details/78519805) 一样的策略，在每一patch上引入GAN loss。具体来说，我们使用4层全卷积鉴别器,该patch鉴别器的有效接受域为 23 × 23 23 \times 2323×23 , PatchGAN策略有助于得到patch级别的密集域距离映射，该映射将用于SRN的后续训练阶段。

补充：patch：图像块，当需要处理的图像分辨率太大而资源受限(比如显存、算力等)时，就可以将图像划分成一个个小块，这些小的图像块就是patch。**为何要划分patch而不使用resize缩小分辨率呢？** **resize操作大多是对图像进行插值处理，本质上一种滤波，在像素级别上会造成损失 划分patch只是把原来的大图分成一个个小图，而这些小图依然是原图的部分，像素值没有改动**，因而在理论上，训练出来模型的上限能够比基于resize得到的图像训练来的高，同时保证了样本均衡。

 小波变换：小波变换是将原始图像与**小波基函数**以及**尺度函数**进行内积运算,所以一个尺度函数和一个小波基函数就可以确定一个小波变换。经过小波变换后图像会生成低频信息和高频信息。低频信息对应于求均值，高频信息对应于求差值。

> 均值是局部的平均值，变化缓慢，属于低频信息，存储图片的轮廓信息，近似信息`
> `差值是局部的波动值，变化较快，属于高频信息，存储图片的细节信息，局部信息，另外含有噪音

> Training Details:
>
> - Training loss:
>     L D S N = α L c o n + β L p e r + γ L a d v G L_{DSN} = \alpha L_{con} + \beta L_{per} + \gamma L_{adv} ^ GLDSN​=αLcon​+βLper​+γLadvG​
>     为稳定训练，我们使用content loss 预训练DSN网络，在25000次预训练迭代后， α , β , γ \alpha , \beta, \gammaα,β,γ 分别设置为 0.01, 1, 和 0.0005。 我们用192×192尺寸的HR裁剪图片训练DSN网络，批大小设置为16个。初始学习率为0.0001，每10000次迭代我们的学习率减半。我们为50000次迭代训练模型。
>
> ![image-20230228231351915](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416073.png)



### [√] B - Domain distance aware traning of Super-Resolution Network

---

- 生词：performance drop 性能下降 alleviate 缓解 incorporate 合并 align 对齐 rational 合理的 adaptively 适应性地

- 经过上述DSN，我们可以生成合成配对数据![image-20230301112039013](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416075.png)。然而y\^g和y\^r之间的域间隙仍然存在。当对合成数据进行训练的SR网络应用于超分辨率真实的LR图像时，训练数据和测试数据之间的领域差距将导致性能下降。为了缓解域偏差问题，我们考虑域自适应设置并将源域标记数据{Y\^g, X\^r}和目的域未标记数据Y\^r在训练SR网络中合并。该自适应策略的核心由域间隙感知训练和域距离加权监督两部分组成。图4显示了领域距离感知训练过程。

![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416076.png)

#### [√] 3.3 Domain-gap aware training（域间隙感知训练）

---

- 在给定源域和目标域的训练样本的情况下，我们利用两个域中不同的损失来充分利用训练数据。对于原域中有监督标签的数据，我们使用loss函数以监督方式训练网络。对目标域中没有标签的数据我们使用 adversrial loss 将输出分布X\^{r→r} = SRN(y\^r)与真实高分辨率图片X\^r分布对齐使其一致。与我们的DSN训练一样，我们在小波段空间引入 GAN losses。

![image-20230301112833203](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416077.png)

- 除了使用目标域引入L_{target,adv}来指导网络训练外，合理利用源域信息对得到好的SRN也很重要。下面介如何利用每个样本的域距离信息来自适应地监督训练SRN网络。

#### [√] 3.4 Domain-distance weighted supervision

---

- 生词：possess 拥有，占有 diverse 多元 more specifically更具体地说。 endow 得天独厚的 respective 各自 supervision 监督 dense 稠密 denote 表示

- 每个样本的Y\^g与真实世界图片域Y\^r存在着域差距。由于来自不同域的图片之间的差距仅存在于其低层次的characters，生成图片的任一部分可能与真实图片之间拥有不同的域距离。当作为源域数据用于训练目标域 SRN时，应根据不同区域到目标域的距离个各自赋予不同的重要性。我们提出了加权监督策略，该方法使用稠密域距离图来自适应的调节每一对![image-20230301121650993](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416078.png)的损失函数值losses。源域中的加权监督损失可以写成如下：

![image-20230301121714578](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416079.png)

- wi是y_i^g的域距离映射，⊙代表逐点乘法。我们利用在DSN训练过程中获得的鉴别器来评估每个样本的域距离映射。注意到鉴别器是训练来从真实世界低分辨率图片patches辨别生成patches的，**鉴别器的输出代表输入来自目标域的概率**。因此，鉴别器输出越大，输入来自目标真实世界LR域的可能性就越高，到目标域的距离就越小。我们直接利用判别器的输出来加权每个局部区域的重要性。我们利用双线性调整器来调整权重图的大小，使其与HR图像保持一致。



#### [√] 3.5 训练细节

---

- 总之，使用域距离感知训练策略 SRN，我们通过最大限度地减少以下损失来训练SRN：

![image-20230301122429231](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416080.png)

> - 同我们训练DSN流程一样，我们首先使用源域 content loss 预训练我们的SRN网络。经25000次预训练迭代，我们使用上述损失函数且参数为：α = 0.01 , β = 1 a n d 、 g a m m a = 0.005 \alpha = 0.01,\beta = 1 and 、gamma = 0.005α=0.01,β=1and、gamma=0.005 来进行另外50000次迭代训练。我们初始化学习率为0.0002并且每10000次迭代对齐减半。
> - 我们的适配策略适用于不同的网络架构。在本文中，我们直接采用ESRGAN 中使用的体系结构作为我们的SRN。
>
> ![image-20230301122850755](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416081.png)

## [√] 4 实验结果域生成数据库

---

#### [√] 4.1 实验设置

---

- 生词：compressed 压缩. Validation database验证集 quantitative定量 comparison 比较

- 我们将DASR方法应用在 AIM数据库上，这个数据集通过应用合成但逼真的降级来清理高质量图像来模拟数据集。我们遵循了挑战赛中靶域超分辨率的实验设置。训练集包括来自Flickr2K数据集的2650个降级未知的噪声压缩图像和来自DIV2K数据集的800个干净的HR图像。我们在AIM挑战赛的验证数据集上进行了实验，该数据集有用于定量比较的配对数据。验证数据集包含100幅退化类型与训练LR图像相同的图像。由于GAN方法侧重于恢复图像的感知质量，因此学习感知图像块相似度(LPIPS)和平均意见得分(MOS)被用作评价不同方法的主要指标。使用不同的方法计算MOS，测试结果以与ground truth并排的方式展示出来。**一张特定图片的最终MOS是不同候选人评价的平均分：0-相同，1-非常相似，2-相似，3-不相似，4-不同。**对于论文中报告的所有MOS值，我们有相同的26个候选者进行用户研究。除了感知指标外，还使用峰值信噪比(PSNR)和结构相似指数(SSIM)作为参考的额外定量指标。

#### [√] 4.2 消融实验

---

为了研究模型中提出的一些结构是否有效而设计的实验，对提出的某结构，将去掉该结构的网络与加上该结构的网络所得到的结进行对比就是ablation study.（控制变量）

- 设置ablation study来验证模型 DASR的效果。我们首先分析了我们对DSN训练的设计选择。在此基础上，给出了实验结果，验证了本文提出的域间隙感知训练策略和域距离加权监督策略的有效性。

- **Better down-sampling network for synthetic paired data generation**
    - 生词： un-preprocessed未经前处理的 quantitative 定量 metrics量度 respective 各自的 denote 表示 residual残留物
    - **DSN改进了以往的方法，直接从未经处理的HR图像中估计LR图像，并在小波空间中采用更好的对抗性损失。**为了评估我们修改的效果，我们结合了不同的设计选择来生成LR图像,我们训练了不同设置的下采样网络，并使用这些模型从AIM验证数据集中的HR图像生成LR图像。我们将生成的LR图像与数据集中的原始LR图像进行比较，不同模型实现的定量度量如表1所示: 文中还给出了不同下采样网络产生的可视化实例。

 ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416082.png)

- 在该表中，HR/双三次LR表示不同下采样网络所使用的各自的输入。而高斯模糊频率分离(GBFS)、小波频率分离(WFS)和RGB表示模型在不同的空间进行对抗性训练：GBFS使用原始图像和高斯模糊图像之间的残差来提取高频分量，我们的WFS方法采用小波变换来提取高频分量，RGB意味着我们直接在RGB图像上引入GAN损耗。**表1中的结果清楚地表明，所提出的DSN结构和小波空间中的对抗性损失都有利于生成更好的LR图像，更接近于目标域中的真实图像。**

- ![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416083.png)
- AIM数据集的Ablation study

- 补充：

    图像超分常用指标

    - [LPIPS](https://codeleading.com/article/78905968289/) :也称为感知损失，用于度量两张图像之间的差别，LPIPS 比传统方法（比如L2/PSNR, SSIM, FSIM）更符合人类的感知情况。最早出现在CVPR2018发表的论文中，LPIPS的值越低表示两张图像越相似，反之，则差异越大。
    - PSNR：峰值信噪比：PSNR的定义由图像 的像素值上限 *L* 和两幅图像间的均方误差(Mean Squared Error，MSE)来表示。在一般情况下，使用8位灰度图像，即 *L*=255。PSNR的值一般在20到40之间变化， 数值越高，表示两幅图像之间的差异越小。当 *L* 固定时，PSNR仅与图像之间的MSE 有关，即仅关注同一位置上像素值之间的差异，而非真实视觉感知。
    - SSIM：融合亮度、对比度、结构三个独立制表形成了结构相似度指标(SSIM)。用于测量图像之间的结构相似性。SSIM值的范围区间在[0,1] 内。 若值越接近1，则说明重建图像与目标图像越相似。

**Domain-gap Aware Training**

- 域距离感知训练是我们模型成功的关键。在表2中，我们给出了实验结果，以显示我们的域距离感知训练的优势。我们使用DSN生成的合成对数据{y\^g, x\^r}或者双三次下采样LR-HR对{y\^b, x\^r}作为源域数据来做实验。正如在3.2中介绍的那样，我们域距离感知训练策略在目标域中引入了额外的对抗损失。为了进行公平的比较，表2中，没有进行域距离感知训练的模型在源域中引入了对抗性损失。在这两种设置下，所提出的领域感知训练策略一致地改善了最终的SR性能。**它帮助SRN生成高质量的HR超分图像，具有更好的MOS分数和更好的LPIPS指数。** 由于MOS指数是通过将主观图像与其对应的参考图像进行比较来获得的，因此具有不同视觉质量的图像可以被归类为同一类别，即相似或不相似。因此，MOS分数并不能全面反映我们的领域感知训练策略的优势。另一方面，LPIPS指数可以清楚地验证我们的领域差距意识训练的有效性。通过在SRN的训练过程中引入目标域数据，即使用双下采样的LR-HR对{Yb，Xr}训练的模型在真实的LR图像上也具有很好的泛化能力。

**Domain-distance weighted Supervision**

- 此外，为了更好地利用源域数据，我们还提出了一种域距离加权监督策略.表2中的实验结果也清楚地表明了域距离加权监督的优势。通过引入权重以自适应地利用成对的训练数据，我们可以得到**表3不同数据集的定量比较。** 请注意，监督训练的ES-RGAN(S.T.ESRGAN)是用成对的训练数据训练的，而其他方法是在没有成对的训练数据的情况下训练的。

![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416084.png)

- 另外，所提出的两种策略是互补的，当两种策略结合在一起时，我们最终的DASR方法比只采用其中一种策略的模型有显著的改进。

#### [√] 4.3 Comparison with State-of-the-Arts

---

- Assumption 假设 similar characteristic 相似特征 exploit利用
- 在这一部分中，我们将我们的方法与其他实际的超分辨方法进行了比较。相比较的方法有Zero-shot SR(ZSSR)、非配对方法用于超分辨率的频率分离方法 （FSSR）、以及循环生成对抗网络cycle-in-cycle generative adversarial networks(CinCGAN)。ZSSR在测试阶段使用Zero-Shot学习策略以适应特定图像的退化模型。FSSR是最近提出的非监督超分方法，还是AIM挑战赛真实世界超分ICCV2019的冠军。此外，我们还提供了预先训练的ESRGAN(记为P.T.ESRGAN)的结果，以供参考，预先训练的ESRGAN模型是在具有双三次下采样LR图像的合成数据集上训练的。表3显示了不同方法实现的量化指标，在图5中，我们还提供了一些不同方法的SR结果的可视化例子。量化指标和可视化例子清楚地表明，我们提出的DASR方法优于竞争模型。**ZSSR和预训练ESRGAN的退化假设不能反映AIM挑战中采用的复杂退化，这两种方法在HR估计中都会产生奇怪的伪影。同时，FSSR方法生成更好的与真实图像特征相似的合成数据来训练模型，能够提供比ZSSR和预先训练的ESRGAN方法更好的SR结果。但是FSSR没有考虑生成的LR图像和真实LR图像之间的域间隙，仍然会在最终输出中产生伪影。新的DASR在训练阶段利用目标域中的信息，能够生成高质量的SR估计，具有视觉上令人愉快的纹理和较少的伪影**

![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416085.png)

图5. 不同方法对2019年ICCV上AIM Challengeon Real World SR图像的测试结果

## [√] 5 Experimental Results on Real-World Images

---

- 在这一部分中，我们将在真实数据集上评估所提出的DASR模型。我们在两个真实的图像SR数据集上进行了实验：RealSR和CameraSR。这两个数据集包含通过调整数码相机焦距收集的真实LR-HR对。我们使用两个数据集的LR图像和DIV2K数据集中的HR图像来部署我们的非监督训练，并在具有配对数据的验证集上对我们的模型进行量化评估。

#### [√] 5.1 Experimental Results on RealSR Dataset

---

作者利用佳能和尼康相机通过调整相机焦距收集595个真实的LR-HR对，并采用图像配准算法实现图像对的对齐。**在我们的实验中，我们使用佳能相机收集的200张LR图像作为我们的真实LR图像，并使用DIV2K中的800张HR图像作为我们的HR图像。** 我们用相同的数据训练我们的DASR模型以及FSSR和CinCGAN模型。经过无监督训练后，我们使用我们的模型在由100个LR-HR对组成的RealSR的验证集中对LR图像进行超分辨。由我们的模型和竞争方法生成的SR结果如表3所示。除了ZSSR、FSSR和预训练的ESRGAN外，我们还提供了监督训练的ESRGAN(记为S.T.ESRGAN)的结果以供参考，它利用训练集中的真实配对数据以完全监督的方式训练ESRGAN模型。DASR在LPIPS指数和MOS评分上都明显优于其他盲超分辨方法.与受监督的ESRGAN相比，DASR获得了与之相当的LPIPS indexes。图6中示出了通过不同方法的一些可视示例。

![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416086.png)

Fig.6: SR results by different methods on testing images from RealSR.





#### [√] 5.2 Exoerimental Results on CameraSR

---

- 生词： subset子集的子集
- 我们还在CameraSR数据集上比较了不同的方法。CameraSR包含分别由iphoneX和Nikon相机捕获的100个LR-HR对。我们在iphoneX子集上测试了我们的方法。由于数据集中的LR和HR图像具有相同的空间大小，因此我们在框架和FSSR模型中去掉了下采样和上采样操作。与我们在RealSR数据集上的实验类似，我们使用Cam-eraSR训练集中的100幅LR图像和DIV2K中的800幅HR图像来训练我们的模型和FSSR。我们的模型和FSSR的SR结果如表3所示。DASR的性能大大优于FSSR。可视示例如图7所示：

![img](https://cdn.jsdelivr.net/gh/Alec-97/alec-s-images-cloud/img/202303011416087.png)

## [√] 6 Conclusions

---

- 我们提出了一种新的无监督真实世界图像SR的DASR框架。在给定未配对数据的情况下，DASR首先训练下采样网络以生成真实世界LR分布中的合成LR图像，然后，利用生成的合成对和真实的LR图像来训练域自适应环境下的SR网络。为了更好地利用源域中的合成数据，我们提出了一种域间隙感知训练策略来引入目标域中的对抗性损失，以及一种域距离加权监督策略。我们在合成数据集和真实数据集上的实验结果证明了我们的方法对于真实世界SR的有效性。























